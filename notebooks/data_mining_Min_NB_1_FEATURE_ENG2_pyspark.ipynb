{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ba5eee-3ed3-49a7-94f4-7ff38a1507f1",
   "metadata": {},
   "source": [
    "# Maestría en Ciencia de Datos e Inteligencia Artificial\n",
    "## Módulo: 09: Minería de Datos\n",
    "### 2025\n",
    "\n",
    "### *Msc Renzo Claure*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c409b-f046-479d-b04e-f9631b666958",
   "metadata": {},
   "source": [
    "Inicializar una sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2373859d-e7d2-4774-9d43-d69151a34190",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySpark en Jupyter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark en Jupyter\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679f850-e3c6-4d34-a237-2719c8134cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcadd49-6a40-40f9-b54c-5af2f51a2b2a",
   "metadata": {},
   "source": [
    "Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c3304-204b-429f-a73c-f13cad237cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"PRACTICAS PYTHON/autos_2.csv\", header=True, inferSchema=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bdaf0-7532-491f-b0d6-b7c36eb547f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f885b1-81be-444f-9cc8-c86b25e0f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(['normalized-losses', 'compression-ratio']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d59c3d-d6e7-4da0-967e-f432c8c42220",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'El número de filas es: {df.count()} y el número de columnas es: {len(df.columns)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441bd12-77b9-4172-ac7d-919d7eb915d7",
   "metadata": {},
   "source": [
    "### Tratamiento de datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22bc45-6c2e-4057-9e3c-b434c403b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79a78f-27c3-4d0a-b881-71ff6917c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls  = df.select(*[sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "nulls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53b908-8d4d-4c7d-98cb-bad89265face",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1362d-c286-4012-8133-f8d1147a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls.toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cea14-d686-41d3-bb3d-96cacb70644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarar nulos\n",
    "df = df.replace('?', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e802b-d473-433e-b547-ee8f456aa24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07222b7d-295b-4330-998f-de2513d724b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('normalized-losses').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3fea3-bd4c-4cb5-bf2e-a196bba07dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971afcce-585b-4bb3-a6bb-4789d33861a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrado de registros\n",
    "df.na.drop().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252890c0-39e1-4b9f-ab2c-5224d6c582a6",
   "metadata": {},
   "source": [
    "#### Rellenar valores faltantes con un valor específico (por ejemplo, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d71825-2a7f-46c4-a36b-b25b314bb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rellenado = df.na.fill(0)\n",
    "\n",
    "# Rellenar valores faltantes con valores específicos para cada columna\n",
    "df_rellenado_especifico = df.na.fill({\n",
    "    \"city-mpg\": 0,\n",
    "    \"num-of-cylinders\": 4,\n",
    "    \"horsepower\": 100,\n",
    "    \"normalized-losses\": 100\n",
    "})\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame rellenado\n",
    "df_rellenado_especifico.select(\"normalized-losses\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9b947-a694-4897-ba7e-fb2b11cc38fd",
   "metadata": {},
   "source": [
    "#### Rellenar datos perdidos con la media, mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a909d8-56f4-4406-b8f4-302d7eee30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738fa607-1a2d-482b-b40d-fba2557eeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['price', 'normalized-losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026db57-2dbb-4faf-a136-8ea8b24edbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisar este codigo... POr que no funciona???\n",
    "df_medias = df.select(mean('price').alias('mean_price'), mean('normalized-losses').alias('mean_nl'))\n",
    "df_medias.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c6f83-a0e5-4c75-ad34-e18af6d96b87",
   "metadata": {},
   "source": [
    "El cambio aún no se ha realizado se puede comprobar ejecutando:  \n",
    "> df_medias[0][0]  \n",
    "> Column<'mean_price[0]'>\n",
    "> \n",
    "Esto es por que aún no se ha realizado la acción que va a concretar la transformación, es necesario aplicar un collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f52611-29be-4013-bbfa-50e2d58656f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es necesario hacer un collect\n",
    "mean_price = df_medias.collect()[0][0]\n",
    "mean_nl = df_medias.collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc758c9-3b40-4acf-998f-0c7a85d384c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mejor opcion para grandes datasets\n",
    "mean_nl = df.select(mean(col(\"normalized-losses\"))).first()[0]\n",
    "mean_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6770321-39ba-4ad5-9ec7-6998c0161f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar por la mediana\n",
    "median_ml = df.select(median(col('normalized-losses'))).first()[0]\n",
    "median_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f30e3d-b743-4c6f-ad04-a1d56aa8e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reemplazamos los valores perdidos\n",
    "df_rellenado_especifico = df.select('normalized-losses').na.fill({'normalized-losses': median_ml})\n",
    "df_rellenado_especifico.select('normalized-losses').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb41682-6634-49e9-b596-f1e3460b3af3",
   "metadata": {},
   "source": [
    "#### Rellenar valores copn la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543df69-a85c-4819-bbb1-126b108931cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('num-of-doors').filter(col('num-of-doors').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8e44a-b4ff-446f-8401-91aeb2ca2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "moda_doors = (\n",
    "    df.groupBy('num-of-doors') #agrupar por la columna\n",
    "    .count() #frecuencias\n",
    "    .orderBy(desc('count')) #ordenar de mayor a menor frecuencia\n",
    "    .select('num-of-doors')\n",
    "    .first()[0]\n",
    ")\n",
    "moda_doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead62a6-a52e-47e3-9f10-c675e410ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rellenar valores nulos en la columna \"num-of-doors\" con la moda\n",
    "df.na.fill({\"num-of-doors\": moda_doors}).select('num-of-doors').filter(col('num-of-doors').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb445f-5289-4c32-9d29-af0a5d87336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media, mediana y moda para varias columnas\n",
    "mean_cmpg = df.select(mean(col(\"city-mpg\"))).collect()[0][0]\n",
    "median_weight = df.approxQuantile(\"curb-weight\", [0.5], 0.01)[0]\n",
    "moda_ncyls = (\n",
    "    df.groupBy(\"num-of-cylinders\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .select(\"num-of-cylinders\")\n",
    "    .first()[0]\n",
    ")\n",
    "\n",
    "# Rellenar valores nulos en múltiples columnas\n",
    "df_rellenado = df.na.fill({\n",
    "    \"city-mpg\": mean_cmpg,  # Rellenar con la media\n",
    "    \"curb-weight\": median_weight,  # Rellenar con la mediana\n",
    "    \"num-of-cylinders\": moda_ncyls  # Rellenar con la moda\n",
    "})\n",
    "\n",
    "# Mostrar el DataFrame con valores nulos rellenados\n",
    "df_rellenado.select(['city-mpg', 'curb-weight', 'num-of-cylinders' ]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217373cf-7916-4eb0-a555-677163cda6f6",
   "metadata": {},
   "source": [
    "**Ejercicio**  \n",
    "Realice la correccion de todos los datos perdidos del set de datos.\n",
    "Recomendación, si requiere cambiar de tipo de dato use:  \n",
    "> from pyspark.sql.types import IntegerType, DoubleType  \n",
    "> df.withColumn(\"city-mpg\", col(\"city-mpg\").cast(DoubleType())) #si requiere numeros reales  \n",
    "> df.withColumn(\"num-of-cylinders\", col(\"num-of-cylinders\").cast(IntegerType())) #si requiere enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e8812-1ef0-4226-8336-a425c51e06c2",
   "metadata": {},
   "source": [
    "### Transformación de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7784018-7257-4a91-bcc4-4dceeb353719",
   "metadata": {},
   "source": [
    "#### Comvertir categorías a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e021094-69e3-48ba-9598-23eff06665d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76578e-9250-4d8a-8812-20582b588cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"fuel-type\", outputCol=\"fuel-index\")\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "indexed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf10f6-f596-44e6-8395-df8338a50e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='fuel-type', outputCol='fuel-index')\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "indexed_df.select(['fuel-type', 'fuel-index']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a27f8-a445-4a6e-ac49-d9150e4ea149",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.groupby(['fuel-type', 'fuel-index']).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd025f30-8497-4b6a-8907-56e586efa1ad",
   "metadata": {},
   "source": [
    "#### Aplicar One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22014b-c1b5-4653-8ab4-ba9078838e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"fuel-index\"],\n",
    "    outputCols=[\"fuel-encoded\"],\n",
    "    dropLast=False  #incluye todas las categorías\n",
    ")\n",
    "\n",
    "encoded_df = encoder.fit(indexed_df).transform(indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4f264-8bf3-4dcb-b127-77221d1cb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.select(['fuel-type', 'fuel-encoded']).filter(col('fuel-type')=='diesel').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c57af3-7612-4194-9ebf-70cfbe4922f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.select(['fuel-type', 'fuel-encoded']).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7873ec8-488e-43f3-b47d-02f71e7d15f9",
   "metadata": {},
   "source": [
    "#### Cerrar la sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5817f3-0470-4db8-8239-0a96cd32bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
